FROM jupyter/pyspark-notebook:latest

# Переключаемся на root для установки
USER root

# Установка Python библиотек
RUN pip install minio boto3 requests

# Скачиваем и устанавлием OpenJDK 11
RUN wget https://github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20.1%2B1/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20.1_1.tar.gz && \
    mkdir -p /opt/java/openjdk11 && \
    tar -xzf OpenJDK11U-jdk_x64_linux_hotspot_11.0.20.1_1.tar.gz -C /opt/java/openjdk11 --strip-components=1 && \
    rm OpenJDK11U-jdk_x64_linux_hotspot_11.0.20.1_1.tar.gz

# Копируем JAR'ы для работы с MinIO (s3a)
COPY ./jars/aws-java-sdk-bundle-1.11.901.jar /opt/jars/
COPY ./jars/hadoop-aws-3.3.1.jar /opt/jars/

# Добавляем JARы в переменную окружения, чтобы Spark мог их подхватить
ENV SPARK_EXTRA_JARS=/opt/jars/aws-java-sdk-bundle-1.11.901.jar,/opt/jars/hadoop-aws-3.3.1.jar

# Устанавливаем переменные окружения для Java
ENV JAVA_HOME=/opt/java/openjdk11
ENV PATH=$JAVA_HOME/bin:$PATH

# Возвращаемся к обычному пользователю jovyan
USER jovyan



